/* ================ Scheduler support ================ */

/**
 * @defgroup thread Thread management
 * @ingroup kernel
 * @brief Cooperative multi-threading support.
 *
 * Typically ETA/OS is at its most useful where there are several concurrent
 * tasks that need to be undertaken at the same time. To support this
 * requirement, ETA/OS offers some kind of light processes called threads.
 * In this context a thread is a sequence of executing software that can be
 * considered to be logically independent from other software that is running
 * on the same CPU.
 *
 * The thread management API contains all functions which are used to
 * manipulate the state of the 'current' thread. The current thread is the
 * context of the thread calling the functions. Notable functions include
 * but not exclude yield(), sleep(), wait() and signal().
 */

/**
 * @defgroup sched Scheduling core
 * @ingroup kernel
 * @brief ETA/OS scheduling support.
 *
 * @section sched-desc Introduction
 * The scheduler is responsible for handling the available CPU time, and
 * distributing it around the available threads. The entry point for the
 * scheduler is the function schedule(). This function will check two
 * value's before it decides to switch context or not. It checks the flag
 * THREAD_NEED_RESCHED_FLAG on the currently running thread, and it checks
 * if the thread selected by the algorithm as 'next' is not equal to the one
 * already running. To manually request a reschedule the following stepds are
 * required:
   @code{.c}
   struct thread *tp = current_thread();

   set_bit(THREAD_NEED_RESCHED_FLAG, &tp->flags);
   schedule();
   @endcode
 *
 * @section sched-other Responsibilities
 * The scheduler is responsible for of switching the context of threads, of
 * course. But there is bunch of other features it is updating:
 *
 * * checking if a thread has used up its time slice;
 * * signaling events which have been signaled from an IRQ;
 * * signaling IRQ threads for threaded IRQ support;
 * * updating the timers and clocksource of the CPU clocksource;
 * * Free-ing the memory of killed threads;
 * * Updating the dynamic priorities of threads in the run queue
 *
 * For this reason it is important that the scheduler gets called regularly.
 */

/**
 * @defgroup mutex Recursive mutex
 * @ingroup sched
 * @brief Thread synchronization support.
 *
 * Threads can use these functions to assert mutual access to shared
 * data. Threads can lock a mutex several times recursively without blocking,
 * as long as that thread already owns the mutex.
 */

/**
 * @defgroup condition Condition variables
 * @ingroup sched
 * @brief Variable synchronization principle.
 *
 * To avoid busy waiting states and / or manual fiddling with locks and event
 * queues, an application can use condition variables to signal each other
 * about events. Threads are removed from the run queue when waiting for
 * a condition to come true using condition variables. This means that
 * other threads get a chance to use the CPU more often.
 *
 * Usage example:
@code{.c}
static struct condition condi;
static uint32_t data = 0;

static void get_data(void)
{
        condition_lock(&condi);
        data = random();
        condition_signal(&condi);
        condition_unlock(&condi);
}

static uint32_t use_data(void)
{
        uint32_t rv;

        condition_lock(&condi);
        while(!data)
                condition_wait(&condi);

        rv = data;
        data = 0UL;
        condition_unlock();

        printf("Data received: %lu\n", rv);
        return rv;
}
@endcode
 */

/**
 * @defgroup ipm Message queue management
 * @ingroup sched
 * @brief Inter-Process messages.
 *
 * API to send message from one thread or process to another in a safe way.
 * All threads expecting a message will be placed on a queue in a waiting
 * state and remain there, untill a message arrives on that specific queue.
 */

/**
 * @defgroup preempt Preemption
 * @ingroup sched
 * @brief Preemption API
 *
 * Preemption is the act of (temporarily) interrupting a task to give other
 * tasks the chance at CPU time. How often the scheduler steps in with preemption
 * can be defined at compile time by changing the time slice.
 */

/**
 * @defgroup edf Earliest Deadline First scheduler
 * @ingroup sched
 * @brief Documentation for the (virtual) earliest deadline first algorithm.
 *
 * @section principle Prinicple
 *
 * The earliest deadline first algorithm is a realtime scheduling algorithm
 * which uses deadlines (time) to determine the next thread to execute.
 * For ETA/OS it is (probably) not possible to archive hard realtime using EDF
 * because:
 *
 * * The scheduling clock is not precise enough
 * * It is extremely hard if not impossible to know before hand how long threads need to execute
 *
 * Therefore, it is a better solution to using virtual deadlines. This means
 * that there is no guarantee whatsoever that the thread will be executed by
 * the time the deadline expires, it is merely used to select the next thread
 * for execution.
 *
 * @section prios Priorities
 *
 * Priorities can be handled by using so called _priority_ _ratios_. A priority
 * is calculated using the nice value of a thread with the following formula:
 *
 * \f$f(p) = \frac{13p}{24} + 10\f$
 *
 * Where:
 * * p is the nice value of the thread
 *
 * The actual deadline can then be calculated using:
 *
 * \f$D = t + f(p)\f$
 *
 * Where:
 * * D is the deadline
 * * t is currently tick on the scheduling clock
 */

/**
 * @defgroup rr Round robin scheduler
 * @ingroup sched
 * @brief The round robin scheduling algorithm.
 */

/**
 * @defgroup fifo FIFO scheduler
 * @ingroup sched
 * @brief First-in First-out scheduler.
 *
 * The FIFO scheduler is a round robin scheduler without priorities. It is
 * most useful as a scheduler for I/O queue's.
 */

/**
 * @defgroup lottery Lottery scheduler
 * @ingroup sched
 * @brief Probabilistic lottery scheduling.
 *
 * The lottery scheduling algorithm is a probabilistic scheduling algorithm.
 * Threads are assigned one or more lottery tickets, and the scheduler will
 * draw a random ticket to select a new thread for execution. The distribution
 * of tickets does not need to be uniform; granting a process more tickets
 * provides it a relative higher chance of execution. A user based priority is
 * transformed into a ticket number using the following function: \n
 *
 * \f$f(x) = \frac{1}{25}x+10\f$ \n
 * where \f$x\f$ is the priority assigned by a user.
 */

/**
 * @defgroup evm Event management
 * @ingroup kernel
 * @brief ETA/OS thread synchronisation.
 */
